{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdA57FylKy38Q+2g/S7XzP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is the list of required files that need to uploaded for this script to run:\n",
        "\n",
        "- `lr_utils.py`\n",
        "- `utils.py`\n",
        "- `diabetes_subset_1000.csv`"
      ],
      "metadata": {
        "id": "mj7Jj65yDTm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9AfM7KPmy4i",
        "outputId": "2d905e47-e07d-4345-9e9c-fb5699475a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import load_diabetes_data_subset_1000, print_metrics\n",
        "from lr_utils import LR, train, evaluate_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.random.manual_seed(73)\n",
        "random.seed(73)"
      ],
      "metadata": {
        "id": "3ZNogd1ynAok"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load BRFSS dataset subset 1000 with 50/50 split\n",
        "x_train, x_test, y_train, y_test = load_diabetes_data_subset_1000()"
      ],
      "metadata": {
        "id": "wl0Q7DcUnCYN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Unencrypted LR Model"
      ],
      "metadata": {
        "id": "zSsXSq9wBJJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "gPRF7AOyoBHZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model, optim, criterion, x_train, y_train, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzkxKjYh9-JB",
        "outputId": "82c6600e-8363-460e-83a6-f9c412729372"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.845106\n",
            "Epoch: 2 \tTraining Loss: 0.599584\n",
            "Epoch: 3 \tTraining Loss: 0.538874\n",
            "Epoch: 4 \tTraining Loss: 0.517495\n",
            "Epoch: 5 \tTraining Loss: 0.507676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, precision, recall, f1, confusion  = evaluate_model(model, x_test, y_test)\n",
        "\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy6qWo3M-Bfb",
        "outputId": "5f07a0f1-3083-4ba0-942a-d0aeafb36dcd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7750\n",
            "Precision: 0.7523\n",
            "Recall: 0.8200\n",
            "F1 Score: 0.7847\n",
            "Confusion Matrix:\n",
            " [[73 27]\n",
            " [18 82]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an Encrypted LR Model on Encrypted Data using Sigmoid Approximation"
      ],
      "metadata": {
        "id": "LIof2tq4o5p_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 1"
      ],
      "metadata": {
        "id": "5Xr84zE4BV6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.125 * x\n",
        "        return enc_x.polyval([0.5, 0.125])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "Uz0QmYX2pDLI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 5\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [31, 26, 26, 26, 26, 26, 31]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 26\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "DV2cq0a7pI55"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll8cLztJpOEc",
        "outputId": "f3290f20-8fc5-4fb2-bc60-6493b04a8add"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 14 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "id": "2xr_v7aEpigZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d115621-4b35-4436-98bb-ff83b7c33e2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.5950000286102295\n",
            "Accuracy at epoch #1 is 0.7350000143051147\n",
            "Accuracy at epoch #2 is 0.7450000047683716\n",
            "Accuracy at epoch #3 is 0.7400000095367432\n",
            "Accuracy at epoch #4 is 0.7549999952316284\n",
            "Accuracy at epoch #5 is 0.7649999856948853\n",
            "\n",
            "Average time per epoch: 51 seconds\n",
            "Final accuracy is 0.7649999856948853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 3"
      ],
      "metadata": {
        "id": "Erh86PxlBwUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "VHH8vFZAB1Yz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 6\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [31, 26, 26, 26, 26, 26, 26, 31]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 26\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "eHsqlFFHCgLk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BN8bsWmC9zR",
        "outputId": "2207e8ff-e862-4cca-b2b0-db42db1079ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 15 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-pC0jpeC_bY",
        "outputId": "c019ead0-d2bf-447d-d6ff-83751323cbb5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.625\n",
            "Accuracy at epoch #1 is 0.7099999785423279\n",
            "Accuracy at epoch #2 is 0.7400000095367432\n",
            "Accuracy at epoch #3 is 0.7400000095367432\n",
            "Accuracy at epoch #4 is 0.75\n",
            "Accuracy at epoch #5 is 0.7599999904632568\n",
            "\n",
            "Average time per epoch: 77 seconds\n",
            "Final accuracy is 0.7599999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 5"
      ],
      "metadata": {
        "id": "miwTdVqvEIt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.191 * x - 0.0046 * x^3 + 0.00004*x^5\n",
        "        return enc_x.polyval([0.5, 0.191, 0, -0.0046, 0, 0.00004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "2DICuNpoEOu8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 7\n",
        "poly_mod_degree = 8192*2\n",
        "coeff_mod_bit_sizes = [31, 26, 26, 26, 26, 26, 26, 26, 31]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 26\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "3xL-fHYZFLT7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfam6xZnFexK",
        "outputId": "3cc56758-1683-4de2-8dc9-9247795e8a59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 36 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMkIJ-E6FjlC",
        "outputId": "9d509d36-a84e-4cdd-c48a-b81a256005c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.3799999952316284\n",
            "Accuracy at epoch #1 is 0.7599999904632568\n",
            "Accuracy at epoch #2 is 0.7400000095367432\n",
            "Accuracy at epoch #3 is 0.7599999904632568\n",
            "Accuracy at epoch #4 is 0.7549999952316284\n",
            "Accuracy at epoch #5 is 0.7749999761581421\n",
            "\n",
            "Average time per epoch: 233 seconds\n",
            "Final accuracy is 0.7749999761581421\n"
          ]
        }
      ]
    }
  ]
}