{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5C/JA7hT8gwwP5Mqet/pu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is the list of required files that need to uploaded for this script to run:\n",
        "\n",
        "- `lr_utils.py`\n",
        "- `utils.py`\n",
        "- `diabetes_subset_1000.csv`"
      ],
      "metadata": {
        "id": "mj7Jj65yDTm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9AfM7KPmy4i",
        "outputId": "04c258dd-74fb-4087-ca08-e5232f3af0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import *\n",
        "from lr_utils import LR, train, evaluate_model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "3ZNogd1ynAok"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_diabetes_data_subset_1000():\n",
        "    data = pd.read_csv(\"diabetes_subset_1000.csv\")\n",
        "    data = data.dropna()\n",
        "    y = torch.tensor(data[\"Diabetes_binary\"].values).float().unsqueeze(1)\n",
        "    data = data.drop(columns=['Diabetes_binary'])\n",
        "    data = (data - data.mean()) / data.std()\n",
        "    x = torch.tensor(data.values).float()\n",
        "    return train_test_split(x, y, test_size=0.2, random_state=73)"
      ],
      "metadata": {
        "id": "NZNpMWzg9pPB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load BRFSS dataset subset 1000 with 50/50 split\n",
        "x_train, x_test, y_train, y_test = load_diabetes_data_subset_1000()"
      ],
      "metadata": {
        "id": "wl0Q7DcUnCYN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Unencrypted LR Model"
      ],
      "metadata": {
        "id": "zSsXSq9wBJJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "gPRF7AOyoBHZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model, optim, criterion, x_train, y_train, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzkxKjYh9-JB",
        "outputId": "0ab133bf-86c8-4d7e-a38f-f8b1c7b34b30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.496032\n",
            "Epoch: 2 \tTraining Loss: 0.495556\n",
            "Epoch: 3 \tTraining Loss: 0.495187\n",
            "Epoch: 4 \tTraining Loss: 0.494895\n",
            "Epoch: 5 \tTraining Loss: 0.494659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, precision, recall, f1, confusion  = evaluate_model(model, x_test, y_test)\n",
        "\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy6qWo3M-Bfb",
        "outputId": "2e697e09-ad0b-4efd-900a-8818e23af833"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7700\n",
            "Precision: 0.7500\n",
            "Recall: 0.8100\n",
            "F1 Score: 0.7788\n",
            "Confusion Matrix:\n",
            " [[73 27]\n",
            " [19 81]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an Encrypted LR Model on Encrypted Data using Sigmoid Approximation"
      ],
      "metadata": {
        "id": "LIof2tq4o5p_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 1"
      ],
      "metadata": {
        "id": "5Xr84zE4BV6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.125 * x\n",
        "        return enc_x.polyval([0.5, 0.125])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "Uz0QmYX2pDLI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 5\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 40]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "DV2cq0a7pI55"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll8cLztJpOEc",
        "outputId": "e6c721a0-7dcf-43a6-ff18-8507bb0d33a3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 14 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "id": "2xr_v7aEpigZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6a0fcd-5764-49ee-d9a6-f93017cc9f72"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.4749999940395355\n",
            "Accuracy at epoch #1 is 0.7599999904632568\n",
            "Accuracy at epoch #2 is 0.75\n",
            "Accuracy at epoch #3 is 0.7350000143051147\n",
            "Accuracy at epoch #4 is 0.7350000143051147\n",
            "Accuracy at epoch #5 is 0.7400000095367432\n",
            "\n",
            "Average time per epoch: 54 seconds\n",
            "Final accuracy is 0.7400000095367432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 3"
      ],
      "metadata": {
        "id": "Erh86PxlBwUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "VHH8vFZAB1Yz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 6\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "eHsqlFFHCgLk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BN8bsWmC9zR",
        "outputId": "1e9fa9c7-bf6e-4f4b-a173-c8dff7902bfb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 16 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-pC0jpeC_bY",
        "outputId": "9c63be43-8f54-45a8-df74-db8b4c7adcae"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.5049999952316284\n",
            "Accuracy at epoch #1 is 0.7649999856948853\n",
            "Accuracy at epoch #2 is 0.7599999904632568\n",
            "Accuracy at epoch #3 is 0.7549999952316284\n",
            "Accuracy at epoch #4 is 0.7649999856948853\n",
            "Accuracy at epoch #5 is 0.7699999809265137\n",
            "\n",
            "Average time per epoch: 83 seconds\n",
            "Final accuracy is 0.7699999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Approximation: Degree 5"
      ],
      "metadata": {
        "id": "miwTdVqvEIt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "\n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"Need at least run one forward iteration\")\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # sigmoid(x) = 0.5 + 0.191 * x - 0.0046 * x^3 + 0.00004*x^5\n",
        "        return enc_x.polyval([0.5, 0.191, 0, -0.0046, 0, 0.00004])\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()\n",
        "\n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "\n",
        "    def decrypt(self):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "2DICuNpoEOu8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create TenSEALContext with multiplicative depth of 7\n",
        "poly_mod_degree = 8192*2\n",
        "coeff_mod_bit_sizes = [40, 30, 30, 30, 30, 30, 30, 30, 40]\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 30\n",
        "ctx_training.generate_galois_keys()"
      ],
      "metadata": {
        "id": "3xL-fHYZFLT7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfam6xZnFexK",
        "outputId": "1c35bd16-4a65-4347-c1d5-9e2773bb6578"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 37 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eelr = EncryptedLR(LR(n_features))\n",
        "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
        "\n",
        "times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    eelr.encrypt(ctx_training)\n",
        "\n",
        "    t_start = time()\n",
        "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
        "        enc_out = eelr.forward(enc_x)\n",
        "        eelr.backward(enc_x, enc_out, enc_y)\n",
        "    eelr.update_parameters()\n",
        "    t_end = time()\n",
        "    times.append(t_end - t_start)\n",
        "\n",
        "    eelr.decrypt()\n",
        "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
        "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
        "\n",
        "\n",
        "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
        "print(f\"Final accuracy is {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMkIJ-E6FjlC",
        "outputId": "5e3a11a4-38e9-42a8-8574-2dad171347be"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch #0 is 0.4699999988079071\n",
            "Accuracy at epoch #1 is 0.6800000071525574\n",
            "Accuracy at epoch #2 is 0.7450000047683716\n",
            "Accuracy at epoch #3 is 0.7450000047683716\n",
            "Accuracy at epoch #4 is 0.7549999952316284\n",
            "Accuracy at epoch #5 is 0.7649999856948853\n",
            "\n",
            "Average time per epoch: 244 seconds\n",
            "Final accuracy is 0.7649999856948853\n"
          ]
        }
      ]
    }
  ]
}