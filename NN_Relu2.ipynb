{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXkUk6npaKQyvUGLPzunPB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is the list of required files that need to uploaded for this script to run:\n",
        "\n",
        "- `nn_utils.py`\n",
        "- `utils.py`\n",
        "- `nn_relu_utils.py`\n",
        "- `diabetes_binary_5050split_health_indicators_BRFSS2015.csv`"
      ],
      "metadata": {
        "id": "HTrtx53ejxyz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsTN29a5dkdN",
        "outputId": "9f7bb164-2240-456a-fb41-37cb69f6a247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import tenseal as ts\n",
        "from time import time\n",
        "from utils import load_diabetes_data_5050,create_dataloader, print_metrics\n",
        "from nn_utils import train, evaluate_model\n",
        "from nn_relu_utils import NeuralNet_Relu2\n",
        "\n",
        "torch.random.manual_seed(73)\n",
        "random.seed(73)"
      ],
      "metadata": {
        "id": "CKS4jkWcd9gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Neural Network on Unencrypted Data"
      ],
      "metadata": {
        "id": "Ckxw8hwjfydR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load BRFSS dataset with 50/50 split\n",
        "x_train, x_test, y_train, y_test = load_diabetes_data_5050()"
      ],
      "metadata": {
        "id": "HS_bXUCfeZh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = create_dataloader(x_train, y_train)\n",
        "test_dl = create_dataloader(x_test, y_test)"
      ],
      "metadata": {
        "id": "VpoFjGIaebNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet_Relu2()\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = train(model, train_dl, criterion, optimizer, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN9o2CYaeeE_",
        "outputId": "ddd42ca3-94dd-4d75-f687-ca2d84a43803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.517529\n",
            "Epoch: 2 \tTraining Loss: 0.505575\n",
            "Epoch: 3 \tTraining Loss: 0.504329\n",
            "Epoch: 4 \tTraining Loss: 0.503680\n",
            "Epoch: 5 \tTraining Loss: 0.503214\n",
            "Epoch: 6 \tTraining Loss: 0.502818\n",
            "Epoch: 7 \tTraining Loss: 0.502558\n",
            "Epoch: 8 \tTraining Loss: 0.502409\n",
            "Epoch: 9 \tTraining Loss: 0.502197\n",
            "Epoch: 10 \tTraining Loss: 0.502029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, precision, recall, f1, confusion = evaluate_model(model, test_dl)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYfuFzemef56",
        "outputId": "59fe2a88-8d6e-43fc-8850-1b843fa0b0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 14139 entries in 0 seconds\n",
            "Accuracy: 0.7576\n",
            "Precision: 0.7248\n",
            "Recall: 0.8318\n",
            "F1 Score: 0.7746\n",
            "Confusion Matrix:\n",
            " [[4822 2236]\n",
            " [1191 5890]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating NN on encrypted data"
      ],
      "metadata": {
        "id": "kZI5sBf9f6xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Encryption Parameters\n",
        "\n",
        "# controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192*2,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale,bits_scale,bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ],
      "metadata": {
        "id": "mgYmOzSuf-rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t_start = time()\n",
        "enc_x_test = [ts.ckks_vector(context, x.tolist()) for x in x_test]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5UQg_Ffg3Vt",
        "outputId": "cc61f40e-bd88-48ad-d7e3-2f5c748c6ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the test-set took 345 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_approx(enc_x):\n",
        "      # We use the polynomial approximation of degree 2\n",
        "      # relu(x) = 0.563059 + 0.5*x + 0.078047*x**2\n",
        "      # from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9378372&tag=1\n",
        "      # which fits the function pretty well in the range [-6,6]\n",
        "      return enc_x.polyval([0.563059, 0.5, 0.078047])\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "\n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "\n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "\n",
        "        self.fc3_weight = torch_nn.fc3.weight.T.data.tolist()\n",
        "        self.fc3_bias = torch_nn.fc3.bias.data.tolist()\n",
        "\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # relu approximation\n",
        "        enc_x = relu_approx(enc_x)\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        # relu approximation\n",
        "        enc_x = relu_approx(enc_x)\n",
        "        # fc3 layer\n",
        "        enc_x = enc_x.mm(self.fc3_weight) + self.fc3_bias\n",
        "        return enc_x\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ],
      "metadata": {
        "id": "qOzQsONrgaJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def encrypted_evaluation(model, enc_x_test, y_test):\n",
        "  t_start = time()\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for enc_x, y in zip(enc_x_test, y_test):\n",
        "        # encrypted evaluation\n",
        "        enc_out = model(enc_x)\n",
        "        # plain comparison\n",
        "        output = enc_out.decrypt()\n",
        "        output = torch.tensor(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        predicted = output >= 0.5\n",
        "        y_true.extend(y.view(-1).tolist())\n",
        "        y_pred.extend(predicted.view(-1).tolist())\n",
        "\n",
        "  t_end = time()\n",
        "  print(f\"Evaluated test_set of {len(y_test)} entries in {int(t_end - t_start)} seconds\")\n",
        "\n",
        "  # Calculate metrics\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "  confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  return accuracy, precision, recall, f1, confusion"
      ],
      "metadata": {
        "id": "oOtEOgg9hKTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model = EncConvNet(model)\n",
        "accuracy, precision, recall, f1, confusion = encrypted_evaluation(enc_model, enc_x_test, y_test)\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "id": "bSoyhFtFhfvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bfe707-94d5-4316-cb0d-4b5f9e7b498c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 14139 entries in 10759 seconds\n",
            "Accuracy: 0.7451\n",
            "Precision: 0.7633\n",
            "Recall: 0.7118\n",
            "F1 Score: 0.7366\n",
            "Confusion Matrix:\n",
            " [[5495 1563]\n",
            " [2041 5040]]\n"
          ]
        }
      ]
    }
  ]
}