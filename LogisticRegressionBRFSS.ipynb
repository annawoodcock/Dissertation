{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "12Ey7NxKmQHC9Tw5C1ULo6qoy9DZ1OXQf",
      "authorship_tag": "ABX9TyPGU5EYYT1bohoWngvIPXwL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below is the list of required files that need to uploaded for this script to run:\n",
        "\n",
        "- `lr_utils.py`\n",
        "- `utils.py`\n",
        "- `/content/diabetes_binary_5050split_health_indicators_BRFSS2015.csv`\n"
      ],
      "metadata": {
        "id": "c9fwoH34XB5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXCDzesOurND",
        "outputId": "40ce9831-7162-4b83-e4cb-1afb264172af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n"
          ]
        }
      ],
      "source": [
        "pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "import numpy as np\n",
        "\n",
        "from utils import load_diabetes_data_5050, print_metrics\n",
        "from lr_utils import LR, train, evaluate_model"
      ],
      "metadata": {
        "id": "0HNbd3DGwDfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load BRFSS dataset with 50/50 split\n",
        "x_train, x_test, y_train, y_test = load_diabetes_data_5050()"
      ],
      "metadata": {
        "id": "8BNAmqReTCZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training LR Model"
      ],
      "metadata": {
        "id": "VueHGHrAzFSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define training parameters\n",
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "4m3AMQUhzOr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jeETP2mhTVdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model, optim, criterion, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKnFsl8rzQ9U",
        "outputId": "3032bad9-08df-4850-9e92-3b749910d428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.874620\n",
            "Epoch: 2 \tTraining Loss: 0.592624\n",
            "Epoch: 3 \tTraining Loss: 0.558967\n",
            "Epoch: 4 \tTraining Loss: 0.544343\n",
            "Epoch: 5 \tTraining Loss: 0.535871\n",
            "Epoch: 6 \tTraining Loss: 0.530366\n",
            "Epoch: 7 \tTraining Loss: 0.526552\n",
            "Epoch: 8 \tTraining Loss: 0.523790\n",
            "Epoch: 9 \tTraining Loss: 0.521724\n",
            "Epoch: 10 \tTraining Loss: 0.520137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, precision, recall, f1, confusion  = evaluate_model(model, x_test, y_test)\n",
        "\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "544CMFwjTXFd",
        "outputId": "93009f1b-a709-45a6-da43-4242df9d660a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7473\n",
            "Precision: 0.7354\n",
            "Recall: 0.7738\n",
            "F1 Score: 0.7541\n",
            "Confusion Matrix:\n",
            " [[5087 1971]\n",
            " [1602 5479]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encrypted Evaluation"
      ],
      "metadata": {
        "id": "izmAVSrtzJ9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "\n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        return enc_out\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "eelr = EncryptedLR(model)"
      ],
      "metadata": {
        "id": "as82Vtqjz1w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "poly_mod_degree = 4096\n",
        "coeff_mod_bit_sizes = [40, 20, 40]\n",
        "# create TenSEALContext\n",
        "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "# scale of ciphertext to use\n",
        "ctx_eval.global_scale = 2 ** 20\n",
        "# this key is needed for doing dot-product operations\n",
        "ctx_eval.generate_galois_keys()"
      ],
      "metadata": {
        "id": "s2XU0zMS0KeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_start = time()\n",
        "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT4WZgi30NSs",
        "outputId": "3117f2a5-bbf0-4502-9187-8ffbf8e3e7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the test-set took 36 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def encrypted_evaluation1(model, enc_x_test, y_test):\n",
        "  t_start = time()\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for enc_x, y in zip(enc_x_test, y_test):\n",
        "        # encrypted evaluation\n",
        "        enc_out = model(enc_x)\n",
        "        # plain comparison\n",
        "        output = enc_out.decrypt()\n",
        "        output = torch.tensor(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        predicted = output >= 0.5\n",
        "        y_true.extend(y.view(-1).tolist())\n",
        "        y_pred.extend(predicted.view(-1).tolist())\n",
        "\n",
        "  t_end = time()\n",
        "  print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
        "\n",
        "  # Calculate metrics\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "  confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  return accuracy, precision, recall, f1, confusion\n"
      ],
      "metadata": {
        "id": "WtA4Nza5UF6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, precision, recall, f1, confusion  = encrypted_evaluation1(eelr, enc_x_test, y_test)\n",
        "\n",
        "print_metrics(accuracy, precision, recall, f1, confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeksMMJSVPXK",
        "outputId": "be25b90c-beae-4214-b0fe-2c1470ad401e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 14139 entries in 74 seconds\n",
            "Accuracy: 0.7322\n",
            "Precision: 0.6740\n",
            "Recall: 0.9013\n",
            "F1 Score: 0.7712\n",
            "Confusion Matrix:\n",
            " [[3971 3087]\n",
            " [ 699 6382]]\n"
          ]
        }
      ]
    }
  ]
}